pipeline {
  agent {
    kubernetes {
      // Each build gets clean environment
      yamlFile './jenkinsfiles/agents/k8s_templates/docker_node_security_pod.yaml' // Fetched from SCM Git repo
    }
  }

  // triggers {
  //   pollSCM 'H/5 * * * *'
  // }

  options {
    // disableConcurrentBuilds()
    buildDiscarder(logRotator(daysToKeepStr: '30', artifactDaysToKeepStr: '1'))
    timestamps()
    timeout(time: 10, unit: 'MINUTES')
  }

  environment { // Keep env block simple; avoid Groovy functions here
    PROJECTDIR = "${env.WORKSPACE}"
    REPORT_TEMPLATE = "${PROJECTDIR}/security_scan/trivy/templates/html.tpl"
    NODE_PROJECT = "${env.PROJECTDIR}/node_project"
    PACKAGE_NAME = '@cv47522/node-project'  // Scoped pkg name
    IMAGE_TAG = "${env.BUILD_NUMBER}"
    // BUILD_DATE and GIT_COMMIT_SHORT are set at runtime in "Init Runtime Vars"
  }

  parameters {
    booleanParam(
      name: 'CHECKOUT_REPO',
      defaultValue: false,
      description: 'Enable extra stage to checkout repo if not using "Pipeline script from SCM" config'
    )
    choice(
      name: 'DOCKERFILE',
      choices: ['Dockerfile_http', 'Dockerfile_express'],
      description: 'Select the Dockerfile to build image'
    )
    string(
      name: 'DOCKER_REGISTRY',
      defaultValue: 'docker.io',
      description: 'Specify the docker registry to pull images'
    )
  }

  stages {
    // stage('Declarative: Checkout SCM') { // Already added by "Pipeline script from SCM"
    //   steps {
    //     checkout scm
    //   }
    // }

    stage('Manual Repo Checkout') { // Or use "Pipeline script from SCM"
      when { expression { params.CHECKOUT_REPO } }
      steps {
        // Install Git in runtime or in agent Dockerfile
        checkout([
          $class: 'GitSCM',
          branches: [[ name: '*/master' ]],
          // branches: [[name: "FETCH_HEAD"]],
          userRemoteConfigs: [[
            url: 'https://github.com/cv47522/jenkins-101.git',
            // credentialsId: 'my-github'
          ]]
        ])

        // Or git clone only recent 5 commits:
        // sh '''
        //   git init .
        //   git pull --depth=5 https://github.com/cv47522/jenkins-101.git master
        // '''
      }
    }

    stage('Init Runtime Vars') {
      steps {
        script {
          // Compute anything that depends on params/env at RUN time (on agent)
          env.IMAGE_NAME       = (params.DOCKERFILE == 'Dockerfile_http'
                                  ? 'plain-node-http-server'
                                  : 'plain-node-express-server')
          env.FULL_IMAGE_NAME  = "cv47522/${env.IMAGE_NAME}"
          env.BUILD_DATE       = new Date().format('yyyy-MM-dd')
          env.GIT_COMMIT_SHORT = (env.GIT_COMMIT ?: 'unknown').take(7)

          echo "Resolved env.IMAGE_NAME=${env.IMAGE_NAME}"
          echo "env.FULL_IMAGE_NAME=${env.FULL_IMAGE_NAME}"
          echo "env.BUILD_DATE=${env.BUILD_DATE}, env.GIT_COMMIT_SHORT=${env.GIT_COMMIT_SHORT}"
        }
      }
    }


    stage('Get Package Version') {
      steps {
        script {
          dir(NODE_PROJECT) {
            // (Method 1) Install Jenkins plugin: Pipeline Utility Steps) Extract version from package.json
            def packageJson = readJSON file: 'package.json'
            String packageVersion = packageJson.version
            // (Method 2) CMD
            // String packageVersion = sh(script: '''
            //   npm pkg get version | tr -d '"'
            // ''', returnStdout: true).trim()

            echo "Resolved ${PACKAGE_NAME} Node.js Package Version: ${packageVersion}"
            currentBuild.displayName = "${PACKAGE_NAME}-${packageVersion}/${BUILD_NUMBER}"

            echo "üöÄ Building ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}"
            echo "üìÖ Build Date: ${env.BUILD_DATE}"
            echo "üîç Git Commit: ${env.GIT_COMMIT}"
          }
        }
      }
    }

    // One-time logins for the whole build
    stage('Registry Login (once)') {
      steps {
        container('docker-client') {
          sh '''
            set -euxo pipefail
            echo "‚è≥ Waiting for Docker daemon..."
            for i in \$(seq 1 60); do
              docker info >/dev/null 2>&1 && break
              sleep 1
            done
            docker info >/dev/null 2>&1 || { echo "‚ùå dockerd not ready"; exit 1; }
          '''
          // Login and push to DockerHub
          withCredentials([
            usernamePassword(credentialsId: 'docker-company-credentials',
              usernameVariable: 'INT_USER', passwordVariable: 'INT_PASS'),
            usernamePassword(credentialsId: 'dockerhub-credentials',
              usernameVariable: 'HUB_USER', passwordVariable: 'HUB_PASS')
          ]) {
            // The same /root/.docker/config.json is reused by all CLI calls in the pod.
            sh """
              set -euxo pipefail
              echo "üîê Login -> internal registry..."
              echo "${INT_PASS}" | docker login "${params.DOCKER_REGISTRY}" -u "${INT_USER}" --password-stdin
              echo "üîê Login -> Docker Hub..."
              # echo "${HUB_PASS}" | docker login -u "${HUB_USER}" --password-stdin
            """
          }
        }
      }
    }

    stage('Dockerfile Linting') {
      steps {
        script {
          container('docker-client') {
            dir(NODE_PROJECT) {
              echo "üîç Linting Dockerfile..."
              // (Method 1) robust in DinD: pipe file via stdin, no bind-mount needed
              int rc = sh(script: """
                  set +e
                  cat "${params.DOCKERFILE}" | docker run --rm -i ${params.DOCKER_REGISTRY}/hadolint/hadolint \
                    hadolint --verbose --failure-threshold warning --format tty - | tee hadolint.out
                  exit ${PIPESTATUS:-0}   # propagate hadolint's exit code through the pipe
                """, returnStatus: true)
              if (rc != 0) {
                error "‚ùå Dockerfile lint failed (>= warning). See hadolint.out above."
              } else {
                echo  "‚úÖ Dockerfile lint passed (no warnings or errors)."
              }

              // (Method 2) if you prefer path-based linting: bind-mount WORKSPACE for DinD
              // sh """
              //   set -euxo pipefail
              //   docker run --rm -v "${WORKSPACE}:${WORKSPACE}" -w "${WORKSPACE}" \
              //     ${params.DOCKER_REGISTRY}/hadolint/hadolint \
              //     hadolint --verbose ${params.DOCKERFILE}
              // """
            }
          }
          // (Method 3)
          // container('hadolint') { // TODO: Add 'hadolint' container to pod.yaml
          //   sh """
          //      set -euxo pipefail
          //      hadolint --verbose --failure-threshold warning ${params.DOCKERFILE}
          //    """
          // }
        }
      }
    }

    stage('Secret Scanning') {
      steps {
        container('docker-client') {
          sh '''
            echo "üîç Scanning for secrets in source code..."
            # Add secret scanning tools here
            grep -r "password\\|secret\\|key\\|token" . || true
          '''
        }
      }
    }

    stage('Build & Test & Package Application') {
      steps {
        container('node') {
          dir(NODE_PROJECT) {
            sh """
              set -euxo pipefail
              echo "üì¶ Installing dependencies..."
              npm ci --omit=dev

              echo "üèóÔ∏è Building application..."
              npm run build || echo "No build script"

              echo "üß™ Running tests..."
              npm test || echo "No tests"

              echo "üìä Packaging application..."
              npm run package || npm pack
              ls -la | grep tgz
            """
          }
        }
      }
    }

    stage('Prepare Docker Context') {
      steps {
        script {
          container('docker-client') {
            if (params.DOCKER_REGISTRY == 'docker.io') {
              sh """
                set -euxo pipefail
                # (Without Proxy)
                docker buildx create --use --name multiarch-builder
              """
            } else {
              sh """
                set -euxo pipefail
                # (With Proxy) Setup buildx for multi-architecture builds
                docker buildx create --use --name multiarch-builder \
                  --driver docker-container \
                  --driver-opt image=${params.DOCKER_REGISTRY}/moby/buildkit:buildx-stable-1
              """
            }
            sh """
              set -euxo pipefail
              docker buildx inspect --bootstrap
              # Show available platforms
              docker buildx ls
            """
          }
        }
      }
    }


    stage('Build Multi-Arch Images') {
      parallel {
        stage('AMD64 Build') {
          steps {
            container('docker-client') {
              dir(NODE_PROJECT) {
                sh """
                  set -euxo pipefail
                  echo "üèóÔ∏è Building AMD64 image..."
                  docker buildx build \
                    --platform linux/amd64 \
                    -f ${params.DOCKERFILE} \
                    --tag  ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-amd64 \
                    --build-arg DOCKER_REGISTRY=${params.DOCKER_REGISTRY} \
                    --build-arg BUILD_DATE="${env.BUILD_DATE}" \
                    --build-arg GIT_COMMIT="${env.GIT_COMMIT}" \
                    --load .
                """
              }
            }
          }
        }

      stage('ARM64 Build') {
          steps {
            container('docker-client') {
              dir(NODE_PROJECT) {
                sh """
                  set -euxo pipefail
                  echo "üèóÔ∏è Building ARM64 image..."
                  docker buildx build \
                    --platform linux/arm64 \
                    -f ${params.DOCKERFILE} \
                    --tag  ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-arm64 \
                    --build-arg DOCKER_REGISTRY=${params.DOCKER_REGISTRY} \
                    --build-arg BUILD_DATE="${env.BUILD_DATE}" \
                    --build-arg GIT_COMMIT="${env.GIT_COMMIT}" \
                    --load .
                """
              }
            }
          }
        }
      }
    }

    stage('Security Scanning (Local Images)') {
      // Local image scan requires mounting docker socket
      parallel {
        stage('Scan AMD64') {
          environment {
            ARCH = 'amd64'
            TRIVY_CACHE_DIR = "${WORKSPACE}/.trivy-cache/${ARCH}"
          }
          steps {
            container('trivy') {
              dir(NODE_PROJECT) {
                sh """
                  set -euxo pipefail
                  echo "üîç Scanning AMD64 image for vulnerabilities..."
                  trivy image ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-${ARCH} \
                    --exit-code 0 --severity HIGH,CRITICAL --format table
                  trivy image ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-${ARCH} \
                    --exit-code 0 --format template \
                    --template "@${env.REPORT_TEMPLATE}" \
                    -o security-report_${env.IMAGE_NAME}-${ARCH}.html
                """
              }
            }
          }
        }

        stage('Scan ARM64') {
          environment {
            ARCH = 'arm64'
            TRIVY_CACHE_DIR = "${WORKSPACE}/.trivy-cache/${ARCH}"
          }
          steps {
            container('trivy') {
              dir(NODE_PROJECT) {
                sh """
                  set -euxo pipefail
                  echo "üîç Scanning ARM64 image for vulnerabilities..."
                  trivy image ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-${ARCH} \
                    --exit-code 0 --severity HIGH,CRITICAL --format table
                  trivy image ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-${ARCH} \
                    --exit-code 0 --format template \
                    --template "@${env.REPORT_TEMPLATE}" \
                    -o security-report_${env.IMAGE_NAME}-${ARCH}.html
                """
              }
            }
          }
        }
      }
    }

    stage('Create Multi-Arch Manifest & Push to DockerHub') {
      steps {
        script {
          container('docker-client') {
            sh """
              set -euxo pipefail
              echo "üì§ Pushing individual architecture images..."
              docker push ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-amd64
              docker push ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-arm64

              echo "üìã Creating and pushing multi-arch manifest..."
              docker manifest create ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG} \
                  ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-amd64 \
                  ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-arm64

              docker manifest create ${env.FULL_IMAGE_NAME}:latest \
                  ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-amd64 \
                  ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-arm64

              docker manifest push ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}
              docker manifest push ${env.FULL_IMAGE_NAME}:latest

              echo "üöÄ Multi-arch image published successfully!"
              docker logout
          """
          }
        }
      }
    }

    stage('Security Scanning (Remote Images)') {
      // (After pushing images) Remote image scan doesn't require mounting docker socket
      parallel {
        stage('Scan AMD64') {
          environment {
            ARCH = 'amd64'
            TRIVY_CACHE_DIR = "${WORKSPACE}/.trivy-cache/${ARCH}"
          }
          steps {
            container('trivy') {
              dir(NODE_PROJECT) {
                sh """
                  set -euxo pipefail
                  echo "üîç Scanning AMD64 image for vulnerabilities..."
                  trivy image --image-src remote \
                    ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-${ARCH} \
                    --exit-code 0 --severity HIGH,CRITICAL --format table
                """
              }
            }
          }
        }

        stage('Scan ARM64') {
          environment {
            ARCH = 'arm64'
            TRIVY_CACHE_DIR = "${WORKSPACE}/.trivy-cache/${ARCH}"
          }
          steps {
            container('trivy') {
              dir(NODE_PROJECT) {
                sh """
                  set -euxo pipefail
                  echo "üîç Scanning ARM64 image for vulnerabilities..."
                  trivy image --image-src remote \
                    ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-${ARCH} \
                    --exit-code 0 --severity HIGH,CRITICAL --format table
                """
              }
            }
          }
        }
      }
    }

    stage('Generate Build Report') {
      steps {
        container('docker-client') {
          sh """
            set -euxo pipefail
            echo "üìä Build Report"
            echo "=============="
            echo "Image: ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}"
            echo "Platforms: linux/amd64, linux/arm64"
            echo "Build Date: ${env.BUILD_DATE}"
            echo "Git Commit: ${env.GIT_COMMIT}"
            echo "Jenkins Build: ${BUILD_NUMBER}"

            # Show image information
            docker images | grep ${env.FULL_IMAGE_NAME} || true
          """
        }
      }
    }
  }

  post {
    always {
      dir(NODE_PROJECT) {
        archiveArtifacts artifacts: '*.tgz,*.html', fingerprint: true
      }
      // container('docker-client') {
      //   // (Optioanl, images already removed after each Pod dies in each build) Cleanup local images to save space
      //   sh """
      //     set -euxo pipefail
      //     echo "üßπ Cleaning up..."
      //     docker rmi ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-amd64 || true
      //     docker rmi ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}-arm64 || true
      //     docker system prune -f
      //     docker buildx rm multiarch-builder || true
      //   """
      // }
      cleanWs()
    }
    success {
      echo "‚úÖ Successfully built and pushed ${env.FULL_IMAGE_NAME}:${env.IMAGE_TAG}"
    }
    failure {
      echo "‚ùå Pipeline failed. Check logs for details."
    }
  }
}